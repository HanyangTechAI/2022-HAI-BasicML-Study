# 09 텍스트를 위한 인공 신경망

## 09-1 순차 데이터와 순환 신경망

### 순차 데이터

1. **순차 데이터** : 텍스트나 시계열 데이터(일정한 시간 간격으로 기록된 데이터)와 같이 순서에 의미가 있는 데이터

- 이 장에서 사용하는 댓글, 즉 텍스트 데어터는 단어의 순서가 중요하므로 이전에 입력한 데이터를 기억하는 기능이 필요합니다.

1. **피드포워드 신경망** : 입력 데이터의 흐름이 앞으로만 전달되는 신경망

- 이전 장에서 배웠던 완전 연결 신경망과 합성곱 신경망이 모두 피드포워드 신경망에 속합니다.

### 순환 신경망

1. **순환 신경망** : 순차 데이터에 잘 맞는 인공 신경망의 한 종류이며 순차 데이터를 처리하기 위해 고안된 순환층을 1개 이상 사용한 신경망

- 타임스텝 : 샘플을 처리하는 한 단계
- 셀 : 순환 신경망에서 층을 부르는 방법
- 은닉 상태 : 셀의 출력
  - 은닉층의 활성화 함수로는 tanh가 많이 사용됩니다.

## 09-2 순환 신경망으로 IMDB 리뷰 분류하기

### IMDB 리뷰 데이터셋

1. **IMDB 리뷰 데이터셋** : 유명한 인터넷 영화 데이터베이스인 imdb.com에서 수집한 리뷰를 감상평에 따라 긍정과 부정으로 분류해 놓은 데이터셋

1. **토큰** : 일반적으로 영어 문장은 모두 소문자로 바꾸고 구둣점을 삭제한 다음 공백을 기준으로 분리하여 매핑하는데 이렇게 분리된 단어

- 특정한 용도로 예약된 정수 : 0(패딩), 1(문장의 시작), 2(어휘 사전에 없는 토큰)

### 순환 신경망

1. **원-핫 인코딩** : 어떤 클래스에 해당하는 원소만 1이고 나머지는 무도 0인 벡터

### 단어 임베딩

1. **단어 임베딩** : 정수로 변환된 토큰을 비교적 작은 크기의 실수 밀집 벡터로 변환

## 09-3 LSTM과 GRU 셀

1. **LSTM** 타임스텝이 긴 데이터를 효과적으로 학습하기 위해 고안된 순환층(입력 게이트, 삭제 게이트, 출력 게이트 역할을 하는 작은 셀 포함)

- 은닉 상태 외에 셀 상태를 출력합니다. 셀 상태는 다음 층으로 전달되지 않으며 현재 셀에서만 순환됩니다.

1. **GRU** : LSTM 셀의 간소화 버전으로 생각할 수 있지만 LSTM 셀에 못지않는 성능을 가짐
