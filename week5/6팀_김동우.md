# CHAPTER 6
## 군집 알고리즘
비지도 학습: 타깃을 모르는 데이터셋 분류에서 사용하는 머신러닝 알고리즘  

* 데이터 확인
```
fruits = np.load('xxx.npy')
plt.imshow(fruits[0], cmap='gray')
plt.show()
```

* subplots()  
  여러 개 그래프를 배열처럼 쌓음
```
fig, axs = plt.subplots(1,2)
axs[0].imshow(fruits[100])
plt.show()
```

* 사과 샘플 픽셀 평균값
```
apple.mean(axis=1)
```

* 평균값과 가까운 사진 고르기
```
abs_diff = np.abs(fruits - apple_mean)
abs_mean = np.mean(abs_diff, axis=(1,2))

apple_index = np.argsort(abs_mean)[:100]
fig, axs = plt.subplots(10, 10, figsize=(10,10))
for i in range(10):
    for j in range(10):
        axs[i, j].imshow(fruits[apple_index[i*10]], cmap='gray_r')
        axs[i, j].axis('off')
plt.show()
```
    
군집: 비슷한 샘플끼리 그룹으로 모음  
클러스터: 군집 알고리즘에서 만든 그룹  

## k-평균
k-평균: 평균값을 자동으로 찾는 군집 알고리즘  
클러스터 중심, 센트로이드: k-평균의 평균값  

* k-평균 구현
```
from sklearn.cluster import KMeans
km = KMeans(n_clusters=3, random_state=42)
km.fit(fruits_2d)
```

* 클러스터를 이미지로 출력
```
import matplotlib.pyplot as plt
def draw_fruits(arr, ratio=1):
    n = len(arr)
    rows = int(np.ceil(n/10))
    cols = n if rows < 2 else 10
    fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False)
    for i in range(rows):
        for j in range(cols):
            if i*10 + j < n:
                axs[i, j].imshow(arr[i*10 +j], cmap='gray_r')
            axs[i, j].axis('off')
    plt.show()
```

* 적절한 k값 찾기  
  엘보우 방법: 클러스터 개수를 늘려가면서 이너셔의 변화 관찰  
  이너셔: 클러스터 중심과 클러스터에 속한 샘플 사이의 거리  
```
inertia = []
for k in range(2, 7):
    km = KMeans(n_cluster=k, rangdom_state=42)
    km.fit(fruits_2d)
    inertia.append(km.inertia_)
plt.plot(range(2, 7), inertia)
plt.show()
```

## 주성분 분석
차원: 데이터가 가진 속성이 특성인데, 머신러닝에서 특성을 부르는 방법  
차원 축소: 비지도 학습 작업, 데이터의 크기를 줄이고 모델 성능 향상  
주성분 분석, PCA: 차원 축소 알고리즘  
주성분: 데이터에 있는 분산이 큰 방향  

* PCA 구현
```
from sklearn.decomposition import PCA
pca = PCA(n_components=50)
pca.fit(fruits_2d)
```

* 원본 데이터 재구성
```
fruits_inverse = pca.inverse_transform(fruits_pca)

fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)
for start in [0, 100, 200]:
    draw_fruits(fruits_reconstruct[start:start+100])
    print("\n")
```

설명된 분산: 주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값  