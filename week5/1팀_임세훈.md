# Ch.06 비지도 학습
## 1. 비지도 학습<span style = "color: grey"> Unsupervised learning</span>
### 비지도 학습이란?
 - 결과정보가 없는 데이터들에 대해 특정 패턴을 찾는 것
 - 데이터의 잠재 구조, 계층 구조 찾기
 - 숨겨진 사용자 집단 찾기
 - 사용 패턴 찾기
  
### 비지도 학습의 대상
 1. 군집화 <span style = "color: grey"> Clustering</span>
 2. 밀도 추정<span style = "color: grey"> Density estimation</span>
 3. 차원 축소<span style = "color: grey"> Dementionality reduction</span>
   ___
## 2. k-평균 알고리즘 <span style = "color: grey"> k-Mean Clustering Algorithm</span>

### 원리
1. 센트로이드 랜덤 선정
2. 샘플에 레이블을 할당하고 센트로이드 업데이트
3. 센트로이드 변화가 없을 때까지 2를 반복
   
### 업데이트 방식
- inertia
  - 샘플과 센트로이드 가이의 거리를 측정하여 모델의 대략적인 성능 확인
  - 특정 클러스터 개수에서 inertia 급격하게 감소

### 최적의 클러스터 개수 찾기
  - inertia가 급격하게 감소하는 지점의 클러스터 개수 찾기
  - 실루엣 score가 1에 가까운 클러스터 개수 찾기

### 문제점
 - 변동성 문제
   - 센트로이드의 초기값에 따라서 결과가 달라질 수 있음
 - Outlier에 예민
   - Outlier 하나하나에 센트로이드가 민감하게 반응
 - 다양한 모양의 클러스터에 취약
   - 거리만을 측정하여 센트로이드 값을 업데이트하기 때문
___
## 3. 차원 축소 <span style = "color: grey">Demensionally Reduction</span>

### 고차원 데이터의 문제점
- 계산 복잡성 증가
- 노이즈 발생 가능성 증가
- 변수들의 상관관계가 많을 수록 모델 성능 감소

### 해결책
- 차원 축소
  - 저차원에서도 데이터를 잘 설명하는 변수들만 사용
___
## 4. PCA <span style = "color: grey">Principal Component Analysis</span>

### 원리
- 원본 데이터의 분산을 보존하는 수직인 기저 집합 찾기
  - 데이터가 Projection된 이후에도 데이터의 분산 보존
  - 차원 축소 이후 데이터의 분산이 큰  방향으로 진행
- 공분산
 - 어떤 변수의 증감에 따라 다른 변수가 따라가는 정도를 의미
 - 이러한 관계를 수치적으로 표현

### 과정
1. Data Centering
  - 데이터의 중심을 평균값으로 조정한다.
  (이후 공분산을 계산할 때 유용)
2. 최적화 문제 계산
  - 벡터를 기저에 투영시켰을 때의 공분산을 계산
  - 공분산이 큰 쪽으로 진행
3. Lagrangian multiplier
  - Lagrangian multiplier을 이용하여 Eigenvectors와 Eigenvalues를 구한다.
4. 적용
  - Eigenvectors, Eigenvalues를 통해 lambda값을 계산(lambda값에 따라 원 데이터의 분산이 잘 보존되는지 알 수 있음)
  
### 데이터 재구성
- 압축된 데이터셋에 PCA변환을 반대로 적용하면 원래 차원으로 되돌릴 수 있음
- 이 경우 원본 데이터와의 차이(재구성 오차)가 발생

### PCA 이외의 차원 축소 기법
- Isomap, t-SNE, MDS 등
- 각각의 기법에 따라 차원 축소 후의 결과가 다르게 나타남
 ___