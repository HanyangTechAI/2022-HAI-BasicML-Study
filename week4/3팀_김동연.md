# 05 트리 알고리즘
> 와인 분류하기
---
## 5-1 결정트리  
<br>

### 결정 트리 (*Decision Tree*)
 **결정 트리**는 예 / 아니오에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘이다. 비교적 예측 과정을 이해하기 쉽고 성능도 뛰어나다. scikit-learn의 **DesicionTreeClassifier**클래스를 이용하여 결정 트리 모델을 다룬다. 
 <br>

 **불순도**는 결정 트리가 최적의 질문을 찾기 위한 기준이다. 사이킷런은 지니 불순도와 엔트로피 불순도를 제공한다.
<br>

 **정보 이득**은 부모 노드와 자식 노드의 불순도 차이이다. 결정 트리 알고리즘은 정보 이득이 최대화되도록 학습한다.
<br>

 결정 트리는 제한 없이 성장하면 훈련 세트에 과대적합되기 쉬우므로 **가지치기**를 통해 결정 트리의 성장을 제한한다. 사이킷런의 결정 트리 알고리즘은 *max_depth, min_samples_split* 등의 여러 가지 가지치기 매개변수를 제공한다.
<br>
 **특성 중요도**는 결정 트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타낸다. 특성 중요도를 계산할 수 있는 것이 결정트리의 또다른 장점이다.
 <br>
 <br>

## 5-2 교차 검증과 그리드 서치  
<br>

### 교차 검증 (*cross validation*)
 **검증 세트**는 하이퍼파라미터 튜닝을 위해 모델을 평가할 때, 테스트 세트를 사용하지 않기 위해 훈련 세트에서 다시 떼어 낸 데이터 세트이다.
<br>

 **교차 검증**은 훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델을 훈련한다. 교차 검증은 이런 식으로 모든 폴드에 대해 검증 점수를 얻어 평균하는 방법이다. <br>
 scikit-learn에서는 **cross_validate()**함수를 이용하여 교차 검증을 수행한다.
<br>
<br>
### 하이퍼파라미터 튜닝
 머신러닝 모델이 학습할 수 없어서 사용자가 지정해야만 하는 파라미터를 **하이퍼파라미터**라고 한다. 머신러닝 라이브러리에선 이런 하이퍼파라미터는 모두 클래스나 메서드의 매개변수로 표현된다.
 <br>

**그리드 서치**는 하이퍼파라미터 탐색을 자동화해 주는 도구이다. 탐색할 매개변수를 나열하면 교차 검증을 수행하여 가장 좋은 검증 점수의 매개변수 조합을 선택한다. 마지막으로 이 매개변수 조합으로 최종 모델을 훈련한다.
<br>

**랜덤 서치**는 연속된 매개변수 값을 탐색할 때 유용하다. 탐색할 값을 직접 나열하는 것이 아니고 탐색 값을 샘플링할 수 있는 확률 분포 객체를 전달한다. 지정된 횟수만큼 샘플링하여 교차 검증을 수행하기 때문에 시스템 자원이 허락하는 만큼 탐색량을 조절할 수 있다.
 <br>
<br>
## 5-3 트리의 앙상블  
<br>

### 앙상블 학습 (*ensemble learning*)
  **앙상블 학습**은 더 좋은 예측 결과를 만들기 위해 여러 개의 모델을 훈련하는 머신러닝 알고리즘을 말한다.
<br>

 **랜덤 포레스트**는 대표적인 결정 트리 기반의 앙상블 학습 방법이다 .부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택하여 트리를 만드는 것이 특징이다.  <br>
 scikit-learn의 **RandomForestClassifier**클래스를 이용하여 랜덤 포레스트 분류 모델을 사용할 수 있다.
<br>

 **엑스트라 트리**는 랜덤 포레스트와 비슷하게 결정 트리를 사용하여 앙상블 모델을 만들지만 부트스트랩 샘플을 사용하지 않는다. 대신 랜덤하게 노드를 분할해 과대적합을 감소시킨다. <br>
 scikit-learn의 **ExtraTreesClassifier**클래스를 이용하여 엑스트라 트리 분류 모델을 사용할 수 있다.
<br>

**그래디언트 부스팅**은 랜덤 포레스트나 엑스트라 트리와 달리 결정 트리를 연속적으로 추가하여 손실 함수를 최소화하는 앙상블 방법이다. 이런 이유로 훈련 속도가 조금 느리지만 더 좋은 성능을 기대할 수 있다. 그래디언트 부스팅의 속도를 개선한 것이 **히스토그램 기반 그레이디언트 부스팅**이며 안정적인 결과와 높은 성능으로 정형 데이터를 다루는 머신러닝 알고리즘 중에 가장 인기가 높다.<br>
scikit-learn의 **GradientBoostingClassifier**클래스를 이용하여 그레이디언트 부스팅 분류 모델을 사용할 수 있고, **HistGradientBoostingClassifier**클래스를 사용하여 히스토그램 기반 그레이디언트 부스팅 분류 모델을 사용할 수 있다.