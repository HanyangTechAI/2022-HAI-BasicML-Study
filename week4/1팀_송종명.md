# 트리 알고리즘

## 1. 결정트리

데이터에 있는 규칙을 통해 데이터셋을 분류/에측하는 지도학습 모델

node: 데이터셋을 분류하는 규칙이 들어가있는 부분.<br>
branch: node안의 규칙을 만족하는지에 따라 분기되는 부분.<br>
root node: 최상위의 node<br>
leaf node: 최하위의 node, 규칙 없이 분류된 데이터셋만 존재

leaf node의 데이터셋의 수에 따라 class가 분류됨 (회귀에서는 leaf node의 데이터셋의 평균을 반환)

___

## 2. 불순도

지니 불순도는 각 샘플의 비율을 제곱해서 더한 다음, 1에서 뺀 값을 의미한다.

$$
G_i = 1 - \sum_{k=1}^{n}p_ik^2\\
H_i = -\sum_{k=1}^{n}p_{ik}\log_2(p_{ik})
$$

- 데이터의 통계정 분산정도 정량화
- 0 ~ 1사이의 값
- 가장 낮은 지니 계수를 가진 feature가 결정트리에서의 root node가 된다.

___

## 3. 앙상블

결정트리의 단점
- 과대적합에 취약하다
- 데이터 셋의 회전과 같은 데이터의 변경과 오류에 취약하다

-> 트리의 성장에 제한을 주고, 앙상블 기법을 활용하여 해결

validation set: 최적의 파라미터를 찾기 위해 사용되는 train set의 일부<br>
train : validation : test = 6 : 2 : 2 가 보통 적절하다.

### 교차 검증(cross-validation)
train set을 K-fold방식으로 쪼개서 모든 데이터를 train과 validation 과정에 사용가능하게끔 하는 기법<br>
보통 5-fold, 10-fold를 교차검증에 사용한다.

### 그리드 서치(grid search)
모든 하이퍼 파라미터의 경우의 수에 대해 교차 검증 결과가 가장 좋은 파라미터 값을 선택하는 방법.

### 랜덤 서치(random search)
탐색 대상 구간 내의 하이퍼 파라미터 값들을 랜덤 샘플링 하여 그 중 가장 좋은 파라미터를 선택하는 방법.

___

## 4. 랜덤 포레스트

부트스트랩: 데이터 셋에서 중복을 허용해서 샘플링 하는 방법.

- 랜덤 포레스트는 훈련을 위한 데이터 샘플을 무작위(부트스트랩 방식)으로 추출한다.
- 훈련에 사용되는 특성의 개수를 조절한다.(보통 전체 개수의 $\sqrt{전체}$개를 선택한다.)
- 분류를 할 때 100개의 결정트리를 만들고 각 트리의 클래스 별 확률을 평균 낸 다음 가장 높은 확률의 클래스를 반환한다.
- 회귀일때는 단순히 각 트리의 값을 평균낸다.

액스트라 트리: 랜덤 포레스트와 동일하나 샘플링 방식이 부트스트랩이 아닌 점이다.

