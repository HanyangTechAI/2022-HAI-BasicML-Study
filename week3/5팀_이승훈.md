## 로지스틱 회귀
분류 모델 중 하나로, 선형 회귀와 동일하게 선형 방정식을 학습한다. 방정식을 통해 나온 값을 다양한 함수에 대입하여 확률로 변환한다.

- 시그모이드 함수: 선형 방정식의 출력을 0과 1 사이의 값으로 압축하여 이진 분류를 위해 사용함

- 소프트맥스 함수: 다중 분류에서 여러 선형 방정식의 출력 결과를 정규화하여 합이 1이 되도록 만듦.

### 주요 메서드

- `LogisticRegression`: 로지스틱 회귀를 위한 클래스
- `predict_proba()`: 이진 분류에선 음성/양성 클래스에 대한 확률을 반환, 다중 분류에선 모든 클래스에 대한 확률을 반환
- `decision_function()`: 모델이 학습한 선형 방정식을 출력

## 확률적 경사 하강법
머신러닝 모델은 꾸준한 학습이 필요하다. 이를 위해 점진적인 학습을 진행해야하고, 대표적인 알고리즘으로 **확률적 경사 하강법**이 있다. 

**확률적 경사하강법**은 훈련 세트에서 샘플을 하나씩 꺼내 손실 함수의 경사를 따라 최적의 모델을 찾는 알고리즘이다.

여기서 전체 데이터를 여러 샘플로 나눠 사용하면 **미니배치 경사 하강법**, 통채로 사용하면 **배치 경사 하강법**이 된다.

- 에포크: 확률적 경사 하강법에서 전체 샘플을 모두 사용하는 한 번 반복을 의미한다.

### 손실 함수
확률적 경사 하강법이 최적화할 대상; 문제에 잘 맞는 손실 함수가 존재한다. 

- 이진 분류: 로지스틱 회귀 손실 함수
- 다중 분류: 크로스 엔트로피 손실 함수
- 회귀 문제: 평균 제곱 오차 손실 함수

### 주요 메서드

- `SGDClassifier`: 확률적 경사 하강법을 사용한 분류 모델을 생성
- `SGDRegressor`: 확률적 경사 하강법을 사용한 회귀 모델을 생성



