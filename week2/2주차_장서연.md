# Ch03. 회귀 알고리즘과 모델 규제
## 회귀 알고리즘
### k-최근접 이웃 회귀
예측하려는 샘플에 가장 가까운 샘플 k개를 선택 > 이웃한 샘플의 타깃값의 평균으로 예측 타깃값 출력
### 과대적합 / 과소적합
* **과대적합**: 훈련 데이터에만 잘 맞게 과하게 최적화 > 실제 데이터와 잘 맞지 않음. (훈련 세트 점수 > 테스트 세트 점수)
* **과소적함**: 모델이 너무 단순하여 적절히 훈련되지 않음. (ex. 훈련 세트의 크기가 매우 작음) (훈련 세트 점수 < 테스트 세트 점수)

## 선형회귀
* 특성이 하나인 경우 어떤 **직선**을 학습
* 학습 속도 & 예측 빠름
* 희소한 데이터셋에서도 유의미한 예측 값 도출 (KNN과의 차이)

## 다중회귀
* 여러 개의 특성을 사용한 선형 회귀
* 특성이 2개인 다중 회귀는 평면을 학습
* 테스트 데이터 개수에 비해 너무 많은 특성은 **과대적합**을 불러옴

## 규제
머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 함.
(선형 회귀 모델의 경우 특성에 곱해지는 계수(기울기)를 작게 만듦)
* 선형 회귀 모델에 규제를 추가한 모델
> 릿지(ridge): 계수를 제곱한 값을 기준으로 규제 적용
```python
from sklearn.linear_model import Ridge
ridge = Ridge()
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled, train_target))
```
> 라쏘(lasso): 계수의 절댓값을 기준으로 규제 적용
```python
from sklearn.linear_model import Lasso
lasso = Lasso()
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
```