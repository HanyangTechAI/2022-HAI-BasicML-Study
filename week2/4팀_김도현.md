### 회귀: 두 변수 사이의 인과관계를 분서하는 방법
### 분류vs회귀: 분류는 여러 클래스 중 하나로 분류하지만 회귀는 임의의 어떤 숫자로 예측한다.

### 결정계수(R^2): 대표적인 회귀 문제의 성능 측정 지표, 1 - sum((실제-예측)^2)/sum((실제-평균)^2), 1에 가까울수록 성능이 좋다.
### 결정계수 추가 설명: 결정계수는 분산을 이용한 지표로, 모델의 설명력을 나타낸다. 실제 타깃의 분산은 (설명할 수 없는 분산 + 설명할 수 있는 분산)으로 이루어지는데 (설명할 수 있는 분산/실제 타깃의 분산)이 결정계수이다. 독립변수가 많아질수록 설명할 수 있는 분산은 늘어나고 결국 종속변수와 별로 관련이 없는 독립변수가 추가해도 결정계수의 값은 증가하는 현상이 발생한다. 따라서 독립변수가 여러개일 때는 조정된 결정계수 값을 이용하여 비교해봐야한다.

### 과대적합: 훈현 데이터에는 잘 맞지만 테스트 데이터에는 잘 맞지 않는 모델, 복잡한 모델에서 일어난다. Low Bias, High Variance
### 과소적합: 훈련 데이터와 테스트 데이터 모두 잘 맞지 않는 모델, 단순한 모델에서 일어난다. High bias, Low Variance
### 특성공학: 기존의 특성을 활용해 새로운 특성을 추출하는 작업 (X -> X^2)
## K-최근접 이웃 회귀
### K-최근접 알고리즘: 어떤 데이터를 분류하고 회귀할 때 근처에 있는 주위 다른 데이터를 이용하는 방법, K는 고려할 주위 데이터의 수를 의미함  (분류의 경우 주위 데이터 중 다수가 차지하는 클래스, 회귀는 주위 데이터의 결과값을 평균)
### 단점: 훈련 데이터의 범위를 벗어난  데이터가 들어오면 값을 예측하기 힘들다.

## 선형회귀
### 선형회귀: 종속변수와 한 개 이상의 독립변수와의 선형관계를 모델링하여 분석하는 방법
### 단순 선형회귀: 선형회귀에서 독립변수가 한 개일 경우
### 다중 선형회귀: 선형회귀에서 독립변수가 여러 개일 경우
### 다항회귀: 다항식을 이용한 선형회귀 (Y = wo + w1X + w2(X^2) + w3(X^3) + ...)

### 규제: 모델이 과대적합되지 않도록 규제하는 방법
## 릿지와 라쏘
### 릿지: 선형회귀 모델에 alpha sum((계수)^2)을 더해 규제를 추가한 모델
### 라쏘: 선형회귀 모델에 alpha sum(absolute(계수))를 더해 규제를 추가한 모델
### 릿지의 경우 계수가 0이 될 수 없지만, 라쏘의 경우는 계수가 0이 되기도 한다. 일반적으로 릿지 모델을 조금 더 선호한다.

