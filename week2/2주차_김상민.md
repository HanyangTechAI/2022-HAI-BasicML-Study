# 발표 2주차

---

발표자 : 윤형서

일자 : 2022-03-24

---

## 내용 정리

### 회귀 알고리즘

- K-최근접 이웃 회귀 알고리즘
- 선형 회귀 알고리즘
- 다항 회귀 알고리즘

### 회귀 알고리즘 훈련-KNeighborsRegressor(매서드)

```python
from sklearn.neighbors import KNeighborsRegressor


knr = KNeighborsRegressor()

knr.fit(trsin_input, train_target)
print(knr.score(test_input, test_target))
```

0.9928094061010639 = 결정계수 R
$$
R^2 = 1 - \frac{(타깃-예측)^2의 합}{(타깃-평균)^2의 합}
$$


### 과소적합

- 훈련세트보다 테스트 세트의 점수가 높거나 두 점수가 모두 낮음
  
- 모델이 너무 단순하거나 훈련세트를 통해 적절히 훈련되지 않음
  

### 과대적합

- 훈련 세트가 테스트에 비해 점수가 너무 큼 
- 모델이 훈련 세트에만 적합해짐 - 과적합
- 규제를 통해 훈련세트를 과도하게 학습하지 못하게 하여 방지(특성에 대한 계수를 줄임)
- 선형 회귀 + 규제 : 릿지,라쏘

### 릿지 회귀(sklearn)

```python
from sklearn.linear_model import Ridge
ridge = Ridge()
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled, train_target))
```

### 라쏘 회귀(sklearn)

```python
from sklearn.linear_model import Lasso
lasso = Lasso()
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
```
