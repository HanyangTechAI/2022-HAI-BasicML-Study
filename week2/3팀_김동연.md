# 03 회귀 알고리즘과 모델 규제
> 농어의 무게 예측하기
---
## 3-1 K-최근접 이웃 회귀  
<br>

### K-최근접 이웃 회귀
 회귀는 샘플을 여러개의 클래스 중 하나로 예측하는 분류와 달리 임의의 수치, 어떤 숫자를 예측하는 지도학습 알고리즘이다.  
 * ex) 내년도 경제성장률 예측하기, 농어의 무게 예측하기  

  

<br>

 k-최근접 이웃 회귀는 k-최근접 이웃 분류 알고리즘과 작동 원리가 비슷하다.  
예측하려는 샘플에 가장 가까운 샘플 k개를 선택하여 이 샘플들의 수치의 평균을 구하고 이 값이 예측 타깃값이 된다.  
<br>
### 결정 계수 $ R^2$  (*coefficient of determination*)
회귀의 경우 모델의 정확도를 평가하는 점수로 **결정계수**라는 값을 사용한다.  
결정계수는 각 샘플의 타깃과 예측한 값의 차이를 제곱하여 더한 후, 타깃과 타깃 평균의 차이를 제곱하여 더한 값으로 나누는 것으로 계산된다.  

따라서 만약 모든 샘플을 타깃의 평균으로 예측한다면 결정계수는 0에 가까워지고, 타깃에 정확히 예측한다면 1에 가까운 값이 된다.  
<br>
### 과대적합 (*overfitting*) vs 과소적합 (*underfitting*)
 **과대적합** 이란 훈련 세트에서는 점수가 높지만 테스트 세트에서는 상대적으로 점수가 낮은 상황이를 말한다. 한마디로 훈련 세트에만 잘 맞는 모델이라고 할 수 있다. 모델이 과대적합되었다면, 실전에 투입되어 새로운 샘플들에 대해 내린 모델의 예측은 정확도가 낮을 것이다.  

 **과소적합** 이란 반대로 훈련 세트에서의 점수보다 테스트 세트에서의 점수가 높거나 두 점수가 모두 낮은 경우이다. 이때는 모델이 너무 단순하여 훈련 세트에도 적절히 훈련되지 않은 경우이다.  

 과대적합과 과소적합 모두 모델을 훈련시킬 때 경계해야하는 상황이며 모델이 훈련 세트와 테스트 세트에서 모두 적절한 점수가 나오도록 조정해야한다.  
 <br>
<br>
## 3-2 선형 회귀  
<br>

### K-최근접 이웃의 한계
 K-최근접 이웃 회귀모델은 가장 가까운 샘플을 찾아 타깃을 평균하므로 새로운 샘플이 훈련 세트의 범위를 벗어나는 경우 합당한 값을 예측할 수 없다.  
<br>
### 선형 회귀 (*liner regression*)
**선형 회귀** 알고리즘은 이름에서 짐작할 수 있듯이 특성이 하나인 경우 어떤 직섭을 학습하는 알고리즘이다. 특성 $a$가 있고 이에 따라 타깃값 $y$를 예측한다면  
$y = ax + b$ 라는 직선을 찾는다.  
이때 모델이 찾은 $a$와 $b$값을 계수또는 가중치라고 부른다.  
<br>
### 다항 회귀 (*polynomial regression*)
특성에 따른 타깃값이 직선의 형태를 띄지않을 때는 직선으로 타깃값을 예측하는데 어려움이 있다. 이럴 땐 특성을 제곱한 항을 추가하여 새로운 다항식을 만들 수 있는데 이 다항식을 사용한 선형 회귀를 **다항 회귀**라고 한다. 다항 회귀를 이용하면 특성에 따라 타깃값을 그래프에서 곡선형태로 예측할 수 있다.  
<br>
<br>
## 3-3 특성 공학과 규제  
<br>

### 다중 회귀 (*multiple regression*)
 여러 개의 특성을 사용한 선형 회귀를 **다중회귀**라고 한다.  
 예를 들어 선형 회귀 모델이 2개의 특성을 사용하여 학습하면 직선이 아닌 평면을 학습하게 된다.  
 따라서 생선의 길이 뿐만이 아니라 높이와 두께 등 다양한 특성을 사용하여 생선의 무게를 예측할 수 있게 된다. 이때 각 특성의 값들을 제곱하거나 서로 곱해서 또다른 특성을 만들어 더 복잡한 방정식을 학습할 수 있는데, 이처럼 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업을 **특성 공학** (*feature engineering)* 이라 한다.  
 <br>
### 규제 (*regularization*)  
**규제**는 머신러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하도록 제한을 두는 것이다. 즉 모델의 과대적합을 막는 역할을 한다. 선형 회귀 모델의 경우 특성에 곱해지는 계수를 작게 만드는 식으로 수행할 수 있다.  
<br>
선형 회귀 모델에 규제를 추가한 모델로는 **릿지**(*ridge*)와 **라쏘**(*lasso*)가 있다.  
릿지는 계수를 제곱한 값을 기준으로 규제를 적용하고, 라쏘는 계수의 절대값을 기준으로 규제를 적용한다. 일반적으로 릿지가 조금더 선호되며, 두 알고리즘 모두 계수의 크기를 줄이지만 라쏘는 아예 0으로 만들 수 있다.
 