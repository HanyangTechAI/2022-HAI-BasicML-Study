# 회귀 알고리즘과 모델 규제

## k-최근접 이웃 회귀

회귀 : 임의의 수치를 예측하는 문제. 타깃값도 임의의 수치가 된다.
k-최근접 이웃 회귀 : k-최근접 이웃 알고리즘을 이용하여 회귀 문제를 해결. 가장 가까운 이웃 샘플을 찾고 이 샘플들의 타깃값을 평균하여 예측으로 삼음.
결정계수(R^2) : 대표적인 회귀 문제의 성능 측정 도구. 1에 가까울수록 좋고, 0에 가깝다면 성능이 나쁜 모델.
과대적합 : 모델의 훈련 세트 성능이 테스트 세트 성능보다 훨씬 높을 때
과소적합 : 훈련 세트와 테스트 세트 성능이 모두 동일하게 낮거나 테스트 세트 성능이 오히려 더 높을 때

1. scikit-learn

- KNeighborsRegressor : k-최근접 이웃 회귀 모델을 만드는 사이킷런 클래스. n_neighbors 매개변수로 이웃의 개수를 지정(기본값 5).
- mean_absolute_error() : 회귀 모델의 평균 절댓값 오차 계산. 첫 번째 매개변수는 타깃, 두 번째 매개변수는 예측값 전달. 타깃과 예측을 뺀 값을 제곱한 다음 전체 샘플에 대해 평균한 값을 반환

2. numpy

- reshape() : 배열의 크기를 바꾸는 메서드. 바꾸고자 하는 배열의 크기를 매개변수로 전달.

## 선형 회귀

선형 회귀 : 특성과 타깃 사이의 관계를 가장 잘 나타내는 선형 방정식 찾기

- 선형 회귀가 찾은 특성과 타깃 사이의 관계는 선형 방정식의 계수 또는 가중치에 저장
  모델 파라미터 : 선형 회귀가 찾은 가중치처럼 머신러닝 모델이 특성에서 학습한 파라미터
  다항 회귀 : 다항식을 사용하여 특성과 타깃 사이의 관계를 나타냄. 비선형일 수 있지만 여전히 선형 회귀로 표현할 수 있음

1. scikit-learn

- LinearRegression : 사이킷런의 선형 회귀 클래스. coef* 속성에서는 특성에 대한 계수 포함, intercept* 속성에는 절편이 저장.

## 특성 공학과 규제

다중 회귀 : 여러 개의 특성을 사용하는 회귀 모델
특성 공학 : 주어진 특성을 조합하여 새로운 특성을 만드는 일련의 작업 과정
릿지 : 규제가 있는 선형 회귀 모델 중 하나이며 선형 모델의 계수를 작게 만들어 과대적합을 완화
라쏘 : 릿지와 달리 계수 값을 아예 0으로 만들 수 있음
하이퍼파라미터 : 머신러닝 알고리즘이 학습하니 않는 파라미터
